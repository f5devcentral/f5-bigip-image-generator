#!/bin/bash
# Copyright (C) 2018-2021 F5 Networks, Inc
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License. You may obtain a copy of
# the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations under
# the License.


set -e
# shellcheck source=src/lib/bash/util/config.sh
source "$(realpath "$(dirname "${BASH_SOURCE[0]}")")/src/lib/bash/util/config.sh"
# shellcheck source=src/lib/bash/util/python_setup.sh
source "$(realpath "$(dirname "${BASH_SOURCE[0]}")")/src/lib/bash/util/python_setup.sh"
# shellcheck source=src/lib/bash/build-image-util.sh
source "$(realpath "$(dirname "${BASH_SOURCE[0]}")")/src/lib/bash/build-image-util.sh"
# shellcheck source=src/lib/bash/util/logger.sh
source "$(realpath "$(dirname "${BASH_SOURCE[0]}")")/src/lib/bash/util/logger.sh"


function trap_cleanup() {
    local artifacts_dir
    artifacts_dir="$(get_config_value "ARTIFACTS_DIR")"

    # Output config before taking snapshot
    "$(realpath "$(dirname "${BASH_SOURCE[0]}")")"/src/bin/output_config.py --artifacts-dir "$artifacts_dir"

    # Take the snapshot of the workspace before cleaning.
    take_snapshot

    local reuse cleaning_msg
    reuse="$(get_config_value "REUSE")"
    cleaning_msg="Cleaning up before EXIT."

    # read file to determine if success return code was ever written
    return_value="$(jq .result "$artifacts_dir"/start_file.json)"

    if [[ "$return_value" == 0 ]]; then
        output_json_file "SUCCESS" "$artifacts_dir"
        publish_telemetry "SUCCESS" "$artifacts_dir"
    else
        output_json_file "FAILURE" "$artifacts_dir"
        publish_telemetry "FAILURE" "$artifacts_dir"
    fi

    # cleaning up any tmp directory
    rm -rf ./tmp.*
    if [[ ! "$reuse" ]]; then
        log_debug "$cleaning_msg 'reuse' parameter was not set, removing the whole directory $artifacts_dir"
        rm -rf "$artifacts_dir"
    else
        log_debug "$cleaning_msg Removing $artifacts_dir/tmp.*"
        rm -rf "$artifacts_dir"/tmp.*
    fi
}

trap trap_cleanup EXIT

function main {
    # Prevent setup log messages from being written to the previous log file
    unset LOG_FILE_NAME

    # Python setup.  We're using the default values and don't want to pass anything (RE: SC2119)
    # shellcheck disable=SC2119
    set_python_environment
    # shellcheck disable=SC2119
    set_python_path

    oem_dir="$(realpath "$(dirname "${BASH_SOURCE[0]}")")/oem"

    if [ -d "$oem_dir" ]; then
        set_python_path "${oem_dir}/src/lib/python"
    fi

    # Check that setup script has been run CHECK_SETUP_JSON_DIR is used so that this works
    # in environments where BASH_SOURCE isn't as expected.
    local check_setup_json_dir
    # shellcheck disable=SC2153
    if [[ -z "$CHECK_SETUP_JSON_DIR" ]]; then
        check_setup_json_dir="$(realpath "$(dirname "${BASH_SOURCE[0]}")")"
        log_info "Set check_setup_json_dir:$check_setup_json_dir"
    else
        check_setup_json_dir="$CHECK_SETUP_JSON_DIR"
        log_info "Use CHECK_SETUP_JSON_DIR for check_setup_json_dir:$check_setup_json_dir"
    fi

    # Config setup.
    if ! init_config "validate" "$@"; then
        error_and_exit "init_config has failed"
    fi
    check_setup "$check_setup_json_dir"

    local cloud iso iso_sig ehf_iso ehf_iso_sig pub_key modules boot_locations platform artifacts_directory \
          config_file cloud_image_name add_ova_eula
    cloud="$(get_config_value "CLOUD")"
    iso="$(get_config_value "ISO")"
    iso_sig="$(get_config_value "ISO_SIG")"
    ehf_iso="$(get_config_value "EHF_ISO")"
    ehf_iso_sig="$(get_config_value "EHF_ISO_SIG")"
    pub_key1="$(get_config_value "ISO_SIG_VERIFICATION_PUBLIC_KEY")"
    encr_type_1="$(get_config_value "ISO_SIG_VERIFICATION_ENCRYPTION_TYPE")"
    pub_key2="$(get_config_value "IMAGE_SIG_PUBLIC_KEY")"
    encr_type_2="$(get_config_value "IMAGE_SIG_ENCRYPTION_TYPE")"
    modules="$(get_config_value "MODULES")"
    boot_locations="$(get_config_value "BOOT_LOCATIONS")"
    platform="$(get_config_value "PLATFORM")"
    config_file="$(get_config_value "CONFIG_FILE")"
    cloud_image_name="$(get_config_value "CLOUD_IMAGE_NAME")"
    add_ova_eula="$(get_config_value "ADD_OVA_EULA")"

    # Initialize logging
    local log_file
    log_file="$(get_config_value "LOG_FILE")"
    if [ "${log_file:0:1}" = '~' ]; then
        error_and_exit "LOG_FILE path starting with '~' is not supported"
    fi
    log_file="$(init_log_file "$log_file")"
    if ! touch "$log_file"; then
        error_and_exit "Do not have permission to write to log file."
    fi
    set_config_value "LOG_FILE" "$log_file"

    local build_start_time
    build_start_time="$(date "+%FT%H:%M:%S")"
 
    # Check if the old log file should be deleted
    local reuse
    reuse="$(get_config_value "REUSE")"
    if [[ ! "$reuse" ]] && [[ -f "$log_file" ]]; then
        local output
        if ! output="$(rm "$log_file")"; then
            error_and_exit "Unable to delete existing log file [${log_file}]: $output"
        fi
    fi

    local log_level
    log_level=$(get_config_value "LOG_LEVEL" | tr '[:lower:]' '[:upper:]')

    create_logger "$log_file" "$log_level"

    # shellcheck disable=SC2181 
    if [[ "$?" -ne 0 ]]; then
        error_and_exit "Logger creation failed"
    fi

    
    # create a temporary directory to hold files downloaded from URL
    local line
    local tmp_dir
    tmp_dir=$(mktemp -d -p .)
    if [ ! -e "$tmp_dir" ]; then
        error_and_exit "Error: Could not create a temporary directory to store the downloaded files"
    fi

    local out_msg_file
    out_msg_file="$(mktemp -p "$tmp_dir" tmp.XXXXXX)"
    if [ ! -e "$out_msg_file" ]; then
        error_and_exit "Error: Could not create a temporary file to get data"
    fi

    # If the vmware EULA is provided and it is a URL, download and store it in tmp_dir
    if [[ -n "$add_ova_eula" ]]; then
        check_eula_src "$add_ova_eula" "$tmp_dir" "$out_msg_file"
        line=$(head -n 1 "$out_msg_file")
        if [[ $line == Error* ]]; then
            error_and_exit "$line"
        fi
        add_ova_eula="$line"
        log_info "Check user-defined OVA EULA passed: $add_ova_eula"
    fi

    # if the iso is a URL download and store it in tmp_dir
    check_iso_src "$iso" "" "$tmp_dir" "$out_msg_file"
    line=$(head -n 1 "$out_msg_file")
    if [[ $line == Error* ]]; then
        error_and_exit "$line"
    fi
    iso="$line"

    local sig_file_ext
    sig_file_ext="$(get_config_value "DEFAULT_SIG_FILE_EXTENSION")"
    local sig_file_loc
    sig_file_loc="$iso""$sig_file_ext"

    if [[ -n "$iso_sig" ]]; then
        check_iso_sig_src "$iso_sig" "$out_msg_file" "$sig_file_loc"
        line=$(head -n 1 "$out_msg_file")
        if [[ $line == Error* ]]; then
            error_and_exit "$line"
        fi
        iso_sig="$line"
    fi

    # Check if ehf_iso is present, either locally or via a URL
    if [[ -n "$ehf_iso" ]]; then
        check_iso_src "$ehf_iso" "ehf flag" "$tmp_dir" "$out_msg_file"
        line=$(head -n 1 "$out_msg_file")
        if [[ $line == Error* ]]; then
            error_and_exit "$line"
        fi
        ehf_iso="$line"

        # Check if a signature file corresponding to ehf_iso is present.
        local ehf_sig_file_loc
        ehf_sig_file_loc="$ehf_iso""$sig_file_ext"
        if [[ -n "$ehf_iso_sig" ]]; then
            check_iso_sig_src "$ehf_iso_sig" "$out_msg_file" "$ehf_sig_file_loc"
            line=$(head -n 1 "$out_msg_file")
            if [[ $line == Error* ]]; then
                error_and_exit "$line"
            fi
            ehf_iso_sig="$line"
        fi
    fi

    if ! verify_iso "$iso" "$iso_sig" "$pub_key1" "$encr_type_1"; then
        # iso verification was skipped or failed with pub_key1
        rc=0
        verify_iso "$iso" "$iso_sig" "$pub_key2" "$encr_type_2" || rc=$?
        if [[ "$rc" -eq 1 ]]; then
            error_and_exit "verify_iso has failed"
        fi
    fi

    #Verify there is enough disk space for the platform if not inside docker
    # shellcheck disable=SC2143
    if [[ ! -f "/.dockerenv" ]] &&  ! grep -q "docker" /proc/1/cgroup ; then
	verify_disk_space
    fi

    if ! verify_iso "$ehf_iso" "$ehf_iso_sig" "$pub_key1" "$encr_type_1"; then
        # iso verification was skipped or failed with pub_key1
        rc=0
        verify_iso "$ehf_iso" "$ehf_iso_sig" "$pub_key2" "$encr_type_2" || rc=$?
        if [[ "$rc" -eq 1 ]]; then
            error_and_exit "verify_iso for has failed"
        fi
    fi

    if ! prepare_artifacts_directory "$iso" "$modules" "$boot_locations" "$platform"; then
        error_and_exit "prepare_artifacts_directory has failed"
    fi
    artifacts_directory="$(get_config_value "ARTIFACTS_DIR")"
    handle_upgrade "$artifacts_directory"

    local script_dir
    script_dir="$(realpath "$(dirname "${BASH_SOURCE[0]}")")"

    
    # Initialize image directory
    init_image_dir "$(realpath "$script_dir")"
    local output_dir
    output_dir="$(get_config_value "IMAGE_DIR")"

    log_info "Starting the image build process"

    if ! copy_metadata_filter_config_files "$artifacts_directory"; then
        error_and_exit "copy_metadata_filter_config_files has failed, check '$log_file' for more details."
    fi

    # extract the version file from the ISOs and populate global vars
    if ! check_version_file "$iso" "$ehf_iso" "$artifacts_directory"; then
        error_and_exit "check_version_file has failed."
    fi

    # Convert the BIG-IP version number into an 8 digit numeric version.
    local version_number
    if ! version_number=$(get_release_version_number "$artifacts_directory/VersionFile.json") || \
            ! is_number "$version_number" ; then
        error_and_exit "Version number retrieval failed. Expected a number but read: $version_number"
    fi
    export BIGIP_VERSION_NUMBER="$version_number"
    # make sure that iso is of a supported version
    validate_iso_version "$platform"

    start_file="${artifacts_directory}/start_file.json"
    if ! jq -M -n \
          --arg build_start_time "$build_start_time" \
        '{ build_start_time: $build_start_time }' \
        > "$start_file"
    then
          log_error "jq failed to create document."
          log_error "Removing file $start_file"
          rm "$start_file"
          exit 1
    fi

    # extract ve.info.json file from the ISO for disk sizing.
    local ve_info_json
    ve_info_json="ve.info.json"
    if ! extract_ve_info_file_from_iso "$iso" "$artifacts_directory" "$ve_info_json"; then
        error_and_exit "extract_ve_info_file_from_iso has failed"
    fi

    # Is this one of the legacy releases?
    if [[ $BIGIP_VERSION_NUMBER -ge 13010002 ]] && [[ $BIGIP_VERSION_NUMBER -lt 14010000 ]] ; then
        # Drop a marker file to signal the prepare_raw_disk about using legacy SELinux
        # labeling scripts.
        touch "$artifacts_directory/.legacy_selinux_labeling"
    fi

    # If cloud platform, and user provided cloud image name, check/fail early
    local cloud_image_opt
    cloud_image_opt="--user-image-name"
    if [[ -n "$cloud" ]] && [[ -n "$cloud_image_name" ]] && [[ "$platform" != "iso" ]]; then
        "${script_dir}"/src/bin/prepare_image.py --artifacts-dir "$artifacts_directory" \
            --platform "$platform" --input "file_placeholder" --check-name \
            "$cloud_image_opt" "$cloud_image_name"
    fi

    # shellcheck disable=SC2181
    if [[ $? -ne 0 ]]; then
        error_and_exit "User-supplied cloud image name check failed, check '$log_file' for more details."
    fi

    # Create metadata file.
    metadata_file="${artifacts_directory}/build-image.json"
    if ! jq -M -n \
          --arg description "User inputs" \
          --arg build_host "$HOSTNAME" \
          --arg build_source "$(basename "$0")" \
          --arg build_user "$USER" \
          --arg platform "$platform" \
          --arg modules "$modules" \
          --arg boot_locations "$boot_locations" \
          --arg config_file "$config_file" \
          --arg iso "$iso" \
          --arg iso_sig "$iso_sig" \
          --arg ehf_iso "$ehf_iso" \
          --arg ehf_iso_sig "$ehf_iso_sig" \
          --arg pub_key "$pub_key" \
        '{ description: $description,
           build_source: $build_source,
           build_host: $build_host,
           build_user: $build_user,
           platform: $platform,
           modules: $modules,
           boot_locations: $boot_locations,
           config_file: $config_file,
           iso: $iso,
           iso_sig: $iso_sig,
           ehf_iso: $ehf_iso,
           ehf_iso_sig: $ehf_iso_sig,
           pub_key: $pub_key }' \
        > "$metadata_file"
    then
          log_error "jq failed to create document."
          log_error "Removing file $metadata_file"
          rm "$metadata_file"
          exit 1
    fi

    if [[ "$platform" == "iso" ]] && [[ ! -d "$oem_dir" ]]; then
	error_and_exit "Modifying iso feature is not supported"
    fi

    if [[ "$platform" == "iso" ]] && [[ -z "$(get_config_value "UPDATE_ISO_RPMS")" ]]; then
        error_and_exit "Build of iso is requested, but changes (UPDATE_ISO_RPMS) are not specified"
    fi

    # check if iso should be updated
    if [[ -n "$(get_config_value "UPDATE_ISO_RPMS")" ]]; then
        local updated_iso_path
        updated_iso_path="$(form_updated_iso_path "$platform" "$iso" "$cloud_image_name" "$artifacts_directory")"
        iso_prefix="$(extract_bigip_prefix_from_iso "$iso")"
        if "$(realpath "$(dirname "${BASH_SOURCE[0]}")")"/oem/src/bin/update_iso.py \
           "$updated_iso_path" "$iso_prefix" "$PRODUCT_VERSION" "$PRODUCT_BASE_BUILD"; then
            log_info "Updated iso with altered rpms"
            if [[ "$platform" == "iso" ]]; then
                # Save an md5sum alongside the packaged disk
                if ! gen_md5 "$updated_iso_path"; then
                    error_and_exit "Failed to generate ${updated_iso_path}.md5"
                fi

                local sig_ext
                sig_ext=$(get_sig_file_extension "$(get_config_value "IMAGE_SIG_ENCRYPTION_TYPE")")
                local sig_file
                sig_file="${updated_iso_path}${sig_ext}"

                sign_file "$updated_iso_path" "$sig_file"
                # shellcheck disable=SC2181
                if [[ $? -ne 0 ]]; then
                    error_and_exit "signing of $updated_iso_path has failed, check '$log_file' " \
                                   " for more details."
                fi
                if [[ ! -f "$sig_file" ]]; then
                    sig_file=""
                fi

                publish_image "$updated_iso_path" "$sig_file" "$output_dir" "updated iso"
                log_info "${BASH_SOURCE[0]} HAS FINISHED SUCCESSFULLY."
                return 0
            else
                # use updated iso from now on
                iso="$updated_iso_path"
            fi
        else
            error_and_exit "Failed to update iso with altered rpms"
        fi
    fi

    # Warn user about slow operations if running without KVM support.
    check_kvm_support

    # Check external ovftool is installed.
    if [[ "$platform" == "aws" ]] || [[ "$platform" == "vmware" ]]; then 
        if ! command -v ovftool > /dev/null 2>&1; then
            error_and_exit "ovftool isn't installed or missing from PATH." \
                    "Please install it before trying again."
        fi
    fi

    # Logging start marker.
    log_info "------======[ Starting disk generation for '$platform' '$modules'" \
            "'$boot_locations' boot-locations. ]======------"

    # Step1: Prepare the raw disk.
    local raw_disk
    raw_disk=$(create_disk_name "raw" "$PRODUCT_NAME" "$PRODUCT_VERSION" \
            "$PRODUCT_BUILD" "$platform" "$modules" "$boot_locations" "$PROJECT_NAME" "$ehf_iso")
    # shellcheck disable=SC2181
    if [[ $? -ne 0 ]]; then
        error_and_exit "create_disk_name has failed, check '$log_file' for more details."
    fi

    raw_disk="$artifacts_directory/$raw_disk"

    # Output json for this step.
    local prepare_disk_json="$artifacts_directory/prepare_raw_disk.json"

    # Check if the configuration overrides LV sizes.
    local lv_sizes_patch_json="lv_sizes_patch.json"
    if "$(realpath "$(dirname "${BASH_SOURCE[0]}")")"/src/bin/increase_lv_sizes.py \
       "$artifacts_directory/$lv_sizes_patch_json"; then
        log_debug "Check if the user wants to increase LV sizes."
    else
        error_and_exit "Failed to check if the user wants to increase LV sizes."
    fi

    # Input json for this step is the ve.info.json file.
    # This step:
    #   => Creates an empty raw disk based on the calculated sizes for partitions and the disk.
    #   => Prepares the customized initramfs and extracts the vmlinuz from the ISO.
    #   => Deploys the ISO on the raw disk.
    #   => Optionally deploys the EHF ISO if provided.
    #   => Boots BIG-IP once for SELinux labeling.
    #   => Returns prepare_disk.json for the next step.
    #
    "${script_dir}/src/bin/prepare_raw_disk" "$artifacts_directory/$ve_info_json" \
                                             "$artifacts_directory/$lv_sizes_patch_json" \
                                             "$platform" "$modules" "$boot_locations" \
                                             "$raw_disk" "$prepare_disk_json" "$iso" "$ehf_iso"

    # shellcheck disable=SC2181
    if [[ $? -ne 0 ]]; then
        error_and_exit "prepare_raw_disk failed, check '$log_file' for more details."
    fi

    # Step2: Convert the raw disk into a virtual-disk of the expected format for the
    # given platform.
    # Output json file for this step.
    local prepare_vdisk_json="$artifacts_directory/prepare_virtual_disk.json"

    local extension
    extension="$(get_disk_extension "$platform")"

    local output_disk
    output_disk=$(create_disk_name "$extension" "$PRODUCT_NAME" "$PRODUCT_VERSION" \
            "$PRODUCT_BUILD" "$platform" "$modules" "$boot_locations" "$PROJECT_NAME" "$ehf_iso")
    # shellcheck disable=SC2181
    if [[ $? -ne 0 ]]; then
        error_and_exit "create_disk_name has failed, check '$log_file' for more details."
    fi

    # Get full paths for staged disk and output disk.
    staged_disk="${artifacts_directory}/staging/${output_disk}"
    log_info "Disk will be staged at: $staged_disk"
    output_disk="${output_dir}/${output_disk}"
    log_info "Disk will be copied to: $output_disk"

    log_info "Create the cloud machine image for '$platform' from a raw image."
    produce_virtual_disk "$platform" "$modules" "$boot_locations" "$raw_disk" \
            "$artifacts_directory" "$prepare_vdisk_json" "$staged_disk" \
            "$add_ova_eula" "$log_file"

    # shellcheck disable=SC2181
    if [[ $? -ne 0 ]]; then
         error_and_exit "produce_virtual_disk failed, check '$log_file' for more details."
    fi


    local sig_file_path
    sig_file_path=$(get_json_key_value "$prepare_vdisk_json" "sig_file")
    # shellcheck disable=SC2181
    if [[ $? -ne 0 ]]; then
        error_and_exit "Error occured during finding sig_file_path from json"
    fi

    log_info "The sig file path: $sig_file_path"
    if [[ -n "$sig_file_path" ]]; then
        sig_file_path="${artifacts_directory}/staging/${sig_file_path}"
    fi

    log_info "Copying staged virtual disk from [${staged_disk}] to [${output_disk}]"
    publish_image "$staged_disk" "$sig_file_path" "$output_dir" "staged virtual disk"

    # Logging finish marker.
    log_info "------======[ Finished disk generation for '$platform' '$modules'" \
            "'$boot_locations' boot-locations. ]======------"

    local no_upload
    no_upload="$(get_config_value "NO_UPLOAD")"
    if is_supported_cloud "$cloud"; then
        if [[ -z "$no_upload" ]]; then
            # If user didn't supply a cloud image name, create one.
            if [[ -z "$cloud_image_name" ]]; then
                cloud_image_opt="--seed-image-name"
                cloud_image_name="$(compose_cloud_image_name "$PRODUCT_NAME" "$PRODUCT_VERSION" \
                                    "$PRODUCT_BUILD" "$modules" "$boot_locations" "$PROJECT_NAME" \
                                    "$ehf_iso")"
            fi
            set_config_value "CLOUD_IMAGE_NAME" "$cloud_image_name"

            "${script_dir}"/src/bin/prepare_image.py --artifacts-dir "$artifacts_directory" \
                --platform "$platform" --input "$staged_disk" \
                "$cloud_image_opt" "$cloud_image_name"
        else
            log_info "The cloud image will be created but not uploaded, due to the --no-upload parameter."
        fi
    else
        set_config_value "HYPERVISOR_IMAGE_NAME" "$(basename "$output_disk")"
        local location_file="${artifacts_directory}/location.json"
        if ! jq -M -n \
              --arg output_dir "$output_dir" \
              '{ location_dir: $output_dir }' \
               > "$location_file"
        then
            log_error "jq failed to create document."
            log_error "Removing file $location_file"
            rm "$location_file"
            exit 1
        fi
    fi 

    # shellcheck disable=SC2181
    if [[ $? -ne 0 ]]; then
        error_and_exit "image creation has failed, check '$log_file' for more details."
    fi

    # set status to result status to SUCCESS
    updated_start_file="$(jq '.result = 0' "$start_file")"
    rm "$start_file"
    echo "$updated_start_file" > "$start_file"

    log_info "${BASH_SOURCE[0]} HAS FINISHED SUCCESSFULLY."
}

main "$@"

exit 0
